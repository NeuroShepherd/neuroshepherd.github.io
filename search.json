[
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "About Me",
    "section": "Experience",
    "text": "Experience\nLMU Open Science Center | Developer | 2022 - Present\n\nGitHub Organization Management\nOpen Source Tutorial Development\n\nBoehringer Ingelheim | Master’s Thesis Student | 2025\n\nShiny App Development\nAnalysis of Clinical Trial Data\n\nNovartis Pharma | Research Intern | 2023\n\nR Package Development\nR Package Validation for Clinical Trials"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Posts",
    "section": "",
    "text": "Aug 6, 2025\n\n\nI had to take a test recently, and I wanted to see if I could stop studying already…\n\n\n\n★ Monte Carlo\n\n\n★ Simulation\n\n\n★ R\n\n\n\n\n\n\n\n\n\n\n\nAug 3, 2025\n\n\nA template for creating new posts\n\n\n\n★ packages\n\n\n★ here’s a long category tag\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts.html#section",
    "href": "posts.html#section",
    "title": "Posts",
    "section": "",
    "text": "Aug 6, 2025\n\n\nI had to take a test recently, and I wanted to see if I could stop studying already…\n\n\n\n★ Monte Carlo\n\n\n★ Simulation\n\n\n★ R\n\n\n\n\n\n\n\n\n\n\n\nAug 3, 2025\n\n\nA template for creating new posts\n\n\n\n★ packages\n\n\n★ here’s a long category tag\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts.html#section-1",
    "href": "posts.html#section-1",
    "title": "Posts",
    "section": "2024",
    "text": "2024\n\n\n\n\n\n\n\n\nordinalsimr\n\n\nNov 17, 2024\n\n\nSimulations of Ordinal Endpoints: A Shiny App\n\n\n\n★ packages\n\n\n★ R\n\n\n\n\n\n\n\n\n\n\n{ordinalsimr} First Release\n\n\nNov 17, 2024\n\n\nFinal checks and the process of submitting to CRAN\n\n\n\n★ packages\n\n\n★ R\n\n\n★ releases\n\n\n\n\n\n\n\n\n\n\nMunich Student Guide\n\n\nNov 17, 2024\n\n\nUnfinished Business: A guide for students in Munich\n\n\n\n★ Germany\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/monte_carlo_passing_test.html",
    "href": "posts/monte_carlo_passing_test.html",
    "title": "Monte Carlo Simulation of Passing a Test",
    "section": "",
    "text": "Load R Libraries\nlibrary(purrr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(dplyr)\n\ntheme_set(theme_minimal())\ntheme_update(plot.background = element_rect(color = \"#06005eff\", linewidth = 1))"
  },
  {
    "objectID": "posts/monte_carlo_passing_test.html#context",
    "href": "posts/monte_carlo_passing_test.html#context",
    "title": "Monte Carlo Simulation of Passing a Test",
    "section": "Context",
    "text": "Context\nI recently had to take a multiple choice test, and I was, frankly, tired of studying for it. The test wasn’t particularly difficult, but it did require quite a bit of rote memorization of dates, historical events, and other facts. Fortunately, this test’s parameters are very well defined: there’s a bank of ~300 possible, publicly-available questions, the test is generated by randomly selecting 33 of those questions, and to pass the test, you only need to get over 50% of the questions correct, which means you can answer just 17 questions correctly to pass.\nAs I was in the middle of my vacation and studying for this test, I kept asking myself “Haven’t I studied enough already?” And so I decided to get an answer to that question with simulations, specifically a Monte Carlo simulation. More precisely, I wanted to find out what percentage of the time I would pass the actual test based on my current level of knowledge, as represented by the total number of practice question I had answered correctly."
  },
  {
    "objectID": "posts/monte_carlo_passing_test.html#monte-carlo-simulations",
    "href": "posts/monte_carlo_passing_test.html#monte-carlo-simulations",
    "title": "Monte Carlo Simulation of Passing a Test",
    "section": "Monte Carlo Simulations",
    "text": "Monte Carlo Simulations\nFirst things first: what is a Monte Carlo simulation? In short, it’s a statistical technique that uses random sampling to obtain numerical results. The idea is to run many simulations (or “trials”) and analyze the results to understand the behavior of the system. In this case, I wanted to simulate the process of taking the test multiple times, each time randomly selecting answers based on my current knowledge level. The key steps in a Monte Carlo simulation are:\n\nDefine the Problem: In this case, the problem is to determine the probability of passing the test based on my current knowledge level.\nModel the System: Create a model that represents the system being studied. Here, the model is the test-taking process, where I randomly select answers based on my knowledge level.\nRun Simulations: Execute the model multiple times, each time with different random inputs to simulate the variability in the system.\nAnalyze Results: Collect and analyze the results to draw conclusions about the system’s behavior.\n\nWith a very basic understanding of Monte Carlo simulation in hand, let’s take a look at the precise parameters I used for my simulation and the code to run it."
  },
  {
    "objectID": "posts/monte_carlo_passing_test.html#simulation-parameters-and-code",
    "href": "posts/monte_carlo_passing_test.html#simulation-parameters-and-code",
    "title": "Monte Carlo Simulation of Passing a Test",
    "section": "Simulation Parameters and Code",
    "text": "Simulation Parameters and Code\nI was working with a total of 308 possible questions, and I had answered 250 of those correctly (mostly through actual knowledge, but a handful through educated guessing or simple chance). The test again consists of 33 randomly selected questions, and I needed to answer at least 17 of those correctly to pass. With those parameters in mind, my chances of passing the test already seem intuitively good as I had answered 81.17% of the questions correctly. But I wanted to see how that translated into actual test-taking scenarios, so I wrote the following R code to run the simulation:\n\n\n\n\nListing 1: Simple Monte Carlo simulation for passing the test\n\n\n\nShow Me the Code!\n# Set parameters\ntotal_questions &lt;- 308\ncorrect_answers &lt;- 250\ntest_questions &lt;- 33\npassing_score &lt;- 17\nn_simulations &lt;- 100000\n\n\n# create a vector to represent practice results\npractice_results &lt;- c(rep(1, correct_answers), rep(0, total_questions - correct_answers))\n\n# sample 33 (i.e. test_questions) of those questions without replacement, and replicate this 10000 times\nsimulation_results &lt;- replicate(n_simulations, {\n  sum(sample(practice_results, test_questions, replace = FALSE))\n})\n\n\n\n\n\nSo what exactly is happening in Listing 1? First, I set the parameters for the simulation, including the total number of questions, the number of questions I had answered correctly, the number of questions on the test, the passing score, and the number of simulations to run.\nNext, I created a vector called practice_results that represents my practice results, where 1 indicates a correct answer and 0 indicates an incorrect answer. This vector is constructed by repeating 1 for the number of correct answers and 0 for the remaining questions.\nFinally, I used the replicate() function to run the simulation n_simulations times. In each iteration, I randomly sampled 33 questions from the practice_results vector without replacement and summed the number of correct answers. The result is stored in the simulation_results vector.\nIn short then, I have a vector of 10,000 test results, each representing the number of questions I answered correctly on a simulated test. Now, I can analyze these results to determine the probability of passing the test."
  },
  {
    "objectID": "posts/monte_carlo_passing_test.html#analyzing-the-results",
    "href": "posts/monte_carlo_passing_test.html#analyzing-the-results",
    "title": "Monte Carlo Simulation of Passing a Test",
    "section": "Analyzing the Results",
    "text": "Analyzing the Results\nA simple first step is to plot the distribution of the number of correct answers across all simulations. This will give us a visual representation of how many times I passed the test.\n\n\nShow Me the Code!\ndata.frame(correct_answers = simulation_results) %&gt;%\nmutate(passed = correct_answers &gt;= 17) %&gt;%\nggplot(aes(x = correct_answers, fill = passed)) +\n  geom_histogram(binwidth = 1, color = \"#241a1aff\", alpha = 0.7) +\n  labs(title = \"Distribution of Correct Answers in Simulated Tests\",\n       x = \"Number of Correct Answers\",\n       y = \"Frequency\") +\n  geom_vline(xintercept = 17, linetype = \"dashed\", color = \"red\", size = 1) +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 20, face = \"bold\"),\n    axis.text = element_text(size = 14),\n    axis.title = element_text(size = 16)\n  ) +\n  scale_x_continuous(limits = c(0, 33)) +\n  scale_fill_manual(values = c(\"TRUE\" = \"#8ef4a7ff\", \"FALSE\" = \"#f48e8eff\"))\n\n\n\n\n\n\n\n\nFigure 1: Distribution of Correct Answers in Simulated Tests\n\n\n\n\n\nFrom the histogram alone, we can see that nearly all of the simulated tests resulted in a passing score, with the vast majority of results clustering around 25 correct answers. Any reasonable interpretation of this histogram would suggest that I should be able to pass the test with a high degree of confidence. But let’s quantify it further by calculating the percentage of simulations that resulted in a passing score.\n\n\nShow Me the Code!\npassing_rate &lt;- mean(simulation_results &gt;= passing_score) * 100\n\n\nThis yields a passing rate of 100%…I think I can stop studying now!"
  },
  {
    "objectID": "posts/monte_carlo_passing_test.html#i-could-have-studied-less",
    "href": "posts/monte_carlo_passing_test.html#i-could-have-studied-less",
    "title": "Monte Carlo Simulation of Passing a Test",
    "section": "I Could Have Studied Less",
    "text": "I Could Have Studied Less\nBut when could I have stopped studying? To answer this, we’ll need to re-run the simulation with different numbers of correct answers on the practice test. Specifically, we’ll run the simulation for every possible number of correct answers from 0 to 308 and calculate the passing rate for each case.\nFirst, let’s set up the simulation for all possible practice test scores:\n\n\n\n\nListing 2: Monte Carlo simulation for all practice test scores\n\n\n\nShow Me the Code!\n# Create empty matrix to hold results\nresults_mat &lt;- matrix(0, 308, 308) \n# Fill lower triangle with 1s to represent valid practice test scores\nresults_mat[lower.tri(results_mat)] &lt;- 1\n# Transpose the matrix to have practice test scores as rows and simulation results as columns\nresults_mat &lt;- t(results_mat)\n# add last column for case of all correct on practice test\nresults_mat &lt;- cbind(results_mat, 1)\n\n\n\n# Run simulations for all practice test scores\nsimulation_all_levels &lt;- results_mat %&gt;%\n  as.data.frame() %&gt;%\n  tibble::tibble() %&gt;%\n  purrr::map(\n    ~replicate(\n      10000, \n      sum(sample(.x, 33, replace = FALSE))\n    )\n  )\n\n\n\n\n\nListing 2 can be thought of in a few different steps, First, I create an empty matrix with 308 rows and 308 columns, where each row represents a different number of correct answers on the practice test (from 0 to 307–not to 308, but we’ll clarify this in a moment)). The lower triangle of the matrix is then filled with 1s which means that each row represents a test score with one more correct answer than the previous row. However, I don’t like to have the rows representing the practice tests, and find it preferable to have the practice test scores as columns, so I transpose the matrix with t(). Finally, I add a last column to represent the case where all questions on the practice test were answered correctly (i.e., 308 correct answers).\nWith the data matrix now set up, we can essentially recreate the simulations we ran in Listing 1, but this time for every possible number of correct answers on the practice test. This means mapping over each column of the data, and running the simulation for each practice test score. The result is a list of vectors, where each vector contains the results of 10,000 simulated tests for a specific number of correct answers on the practice test.\nSo, what can we do with these results? We can calculate the probability of passing the test for each number of correct answers on the practice test, and then plot the results to see how the probability of passing changes as the number of correct answers increases.\n\n\nShow Me the Code!\n# Ggplot only\n\n# simulation_all_levels %&gt;%\n#   map_dbl(\n#     ~sum(.x &gt;= 17)/10000\n#   ) %&gt;%\n#   tibble::tibble(passig_probability = .) %&gt;%\n#   mutate(number_correct_practice = row_number()) %&gt;%\n#   ggplot(aes(number_correct_practice, passig_probability)) +\n#   geom_point() +\n#   geom_line() +\n#   theme(\n#     plot.title = element_text(hjust = 0.5, size = 20, face = \"bold\"),\n#     axis.text = element_text(size = 14),\n#     axis.title = element_text(size = 16)\n#   ) +\n#   labs(\n#     title = \"Probability of Passing Test Based on Practice Test Scores\",\n#     x = \"Number of Correct Answers on Practice Test\",\n#     y = \"Probability of Passing\"\n#   )\n\n\n## Plotly solution\n\nresults_with_ci &lt;- simulation_all_levels %&gt;%\n  set_names(0:(length(simulation_all_levels) - 1)) %&gt;%  # Name the list elements\n  map_dfr(\n    ~{\n      successes &lt;- sum(.x &gt;= 17)\n      trials &lt;- length(.x)\n      proportion &lt;- successes / trials\n      ci &lt;- binom.test(successes, trials)$conf.int\n      tibble(\n        passing_probability = proportion,\n        lower_ci = ci[1],\n        upper_ci = ci[2]\n      )\n    },\n    .id = \"number_correct_practice\"\n  ) %&gt;%\n  mutate(number_correct_practice = as.numeric(number_correct_practice))\n\n\n\nribbon_plot &lt;- results_with_ci %&gt;%\n  mutate(upper_ci = round(upper_ci, 4),\n    lower_ci = round(lower_ci, 4)) %&gt;%\n  rename(\n    \"No. Correct Practice\" = number_correct_practice,\n    \"Passing Probability\" = passing_probability,\n    \"Lower 95% CI\" = lower_ci,\n    \"Upper 95% CI\" = upper_ci\n  ) %&gt;%\n  ggplot(aes(x = `No. Correct Practice`, y = `Passing Probability`)) +\n  geom_ribbon(aes(ymin = `Lower 95% CI`, ymax = `Upper 95% CI`), alpha = 0.4, fill = \"blue\") +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 20, face = \"bold\"),\n    axis.text = element_text(size = 14),\n    axis.title = element_text(size = 16)\n  ) +\n  labs(\n    title = \"Probability of Passing Test\",\n    subtitle = \"Across All Possible Practice Test Scores\",\n    x = \"Number of Correct Answers on Practice Test\",\n    y = \"Probability of Passing\"\n  ) \n\n\nplotly::ggplotly(ribbon_plot) \n\n\n\n\n\n\n\n\nFigure 2: Probability of Passing the Test Based on Practice Test Scores\n\n\n\n\nNote that I’ve also taken the liberty of adding confidence intervals to the plot, which can be done by calculating the proportion of passing scores and the confidence intervals for each practice test score. This can be done using the binom.test() function in R, which provides a confidence interval for the proportion of successes in a binomial distribution. Moreover, the plot.\nThe overall form of Figure 2 is not particularly surprising: the more questions you answer correctly on the practice test, the higher your probability of passing the actual test, and correctly answering half of the questions on the practice yields a 95% confidence interval of \\([48.95, 50.91]\\%\\) probability of passing the examine. There seems to be an inflection point of diminishing marginal returns around 175 correct answers on the practice test, where the probability of passing the actual test increases at a slower rate as the number of correct answers increases. This is likely due to the fact that once you have a solid understanding of the material, additional practice may not significantly improve your chances of passing."
  },
  {
    "objectID": "posts/monte_carlo_passing_test.html#finding-the-optimal-practice-test-score",
    "href": "posts/monte_carlo_passing_test.html#finding-the-optimal-practice-test-score",
    "title": "Monte Carlo Simulation of Passing a Test",
    "section": "Finding the “Optimal” Practice Test Score",
    "text": "Finding the “Optimal” Practice Test Score\nJust for fun, let’s model this mathematically and try to find the point at which we experience diminishing returns in studying more practice questions. Based on the form of the plot, the function that describes the probability of passing the test based on the number of correct answers on the practice test is a sigmoid function, which can generally be expressed as:\n\\[\nP(x) = \\frac{1}{1 + e^{-x}}\n\\tag{1}\\]\nHowever, this function is the most simple version of the sigmoid i.e. it has no parameters adjusting the steepness or midpoint of the curve. The general form of the sigmoid function is:\n\\[\nP(x) = \\frac{L}{1 + e^{-k(x - x_0)}}\n\\tag{2}\\]\nwhere: - \\(P(x)\\) is the probability of passing the test given \\(x\\) correct answers on the practice test, - \\(L\\) is the maximum value of the function (in this case, the maximum probability of passing the test), - \\(k\\) is the steepness of the curve, - \\(x_0\\) is the value of \\(x\\) at which the function reaches its midpoint (i.e., the point of maximum growth which should be at 154 correct practice answers).\n\nFitting the Sigmoid Model\nWith this, let’s first fit a sigmoid model to our data in R so we have actual parameters to work with. The results of this model will give us the parameters \\(L\\), \\(k\\), and \\(x_0\\) that we can use to analyze the inflection point of the sigmoid function. The output of the nls() function will provide estimates for these parameters, which we can then use to find the inflection point.\n\n\n\n\nListing 3: Fitting a Sigmoid Model to the Data\n\n\n\nShow Me the Code!\n### NLS exact code\n# L_fixed &lt;- 1          # Set your desired value for L\n# x0_fixed &lt;- 154         # Set your desired value for x0\n\n# # Custom sigmoid model function with L and x0 fixed\n# sigmoid_fixed &lt;- function(k, number_correct_practice) {\n#   L_fixed / (1 + exp(-k * (number_correct_practice - x0_fixed)))\n# }\n\n# # Fit the model\n# sigmoid_model_fixed &lt;- nls(\n#   passing_probability ~ sigmoid_fixed(k, number_correct_practice),\n#   data = results_with_ci,\n#   start = list(k = 0.1),\n#   control = nls.control(maxiter = 200),\n#   algorithm = \"port\",\n#   lower = c(k = 0),\n#   upper = c(k = 10)\n# )\n\n\nsigmoid_model &lt;- nls(\n  passing_probability ~ L / (1 + exp(-k * (number_correct_practice - x0))),\n  data = results_with_ci,\n  start = list(\n    L = max(results_with_ci$passing_probability, na.rm = TRUE),\n    k = 0.1,\n    x0 = median(results_with_ci$number_correct_practice)\n  ),\n  control = nls.control(maxiter = 200),\n  algorithm = \"port\",\n  lower = c(L = 0, k = 0, x0 = min(results_with_ci$number_correct_practice)),\n  upper = c(L = 1.5 * max(results_with_ci$passing_probability, na.rm = TRUE), k = 10, x0 = max(results_with_ci$number_correct_practice))\n)\n\nsigmoid_model\n\n\n\n\n\nNonlinear regression model\n  model: passing_probability ~ L/(1 + exp(-k * (number_correct_practice -     x0)))\n   data: results_with_ci\n        L         k        x0 \n  1.00318   0.06794 154.11644 \n residual sum-of-squares: 0.01073\n\nAlgorithm \"port\", convergence message: both X-convergence and relative convergence (5)\n\n\nThe sigmoid model has an \\(L\\) value of 1.0032, a \\(k\\) value of 0.0679, and an \\(x_0\\) value of 154.1164.\n\\(L\\) technically should not be greater than 1, but in this case it is ever so slightly above 1 simply as a result of the fitting process. I’m going to offend mathematicians (and probably statisticians) here and simply make this 1. Meanwhile, \\(x_0\\) came out to essentially be the value of 154 that it should be, and I will likewise round this down to 154 for the modeling. The key parameter we gain from modeling is \\(k\\), which is the steepness of the curve. A larger \\(k\\) value indicates a steeper curve, meaning that the probability of passing the test increases more rapidly as the number of correct answers on the practice test increases. A smaller \\(k\\) value indicates a flatter curve, meaning that the probability of passing the test increases more slowly as the number of correct answers on the practice test increases.\nNow that we have the parameters of the sigmoid function, we can develop our mathematical model of the probability of passing the test based on the number of correct answers on the practice test:\n\\[\nP(x) = \\frac{1}{1 + e^{-0.0677(x -154)}}\n\\tag{3}\\]\nWith this model, we can now move on to finding the\n\n\nFinding the “Inflection Point”\nTraditionally, when talking about the inflection point of a function, we are referring to the point at which the curve changes concavity. In the case of a sigmoid function, this is the point at which the function transitions from being concave up to concave down, or vice versa. Put in the context of our test-taking scenario, this is the midpoint of the sigmoid function, where the rate of increase in the probability of passing the test is at its maximum. This point can be found at the value of \\(x\\) where the second derivative of the sigmoid function is equal to zero. However, this is not the “inflection point” I’m interested in here for two main reasons.\nFirst, this traditional inflection point will be right at 154/308 correct practice questions, which, in any practical scenario, is simply not a sufficient point at which one should stop studying. In other words, we would expect someone to continue learning the answers to practice questions beyond this point of diminishing marginal returns. Second, my goal is to strike an appropriate balance between the probability of passing the test and the number of questions one needs to learn. So where do I think this is? Let’s take a look at Figure 3 to get a sense.\nThis plot shows a basic sigmoid function on the range \\([-10, 10]\\), and I’ve plotted a single point that I think is of significance at \\(x=2.2\\). This point represents a visual estimation of the “inflection point” I’m interested in here as this seems to be the point at which change in the change of learning rate begins to accelerate. In the context of learning these practice questions, this is the point at which the value in learning the answers to additional questions begins to take a nosedive.\n\n\nShow Me the Code!\n# Define the sigmoid function and its derivatives\nsigmoid &lt;- function(x, L = 1, k = 1, x0 = 0) {\n  L / (1 + exp(-k * (x - x0)))\n}\n\nsigmoid_derivative &lt;- function(x, L = 1, k = 1, x0 = 0) {\n  k * L * exp(-k * (x - x0)) / (1 + exp(-k * (x - x0)))^2\n}\n\nsigmoid_second_derivative &lt;- function(x, L = 1, k = 1, x0 = 0) {\n  k^2 * L * exp(-k * (x - x0)) * (1 - exp(-k * (x - x0))) / (1 + exp(-k * (x - x0)))^3\n}\n\nsigmoid_third_derivative &lt;- function(x, L = 1, k = 1, x0 = 0) {\n  k^3 * L * exp(-k * (x - x0)) * (1 - 4 * exp(-k * (x - x0)) + exp(-2 * k * (x - x0))) / (1 + exp(-k * (x - x0)))^4\n}\n\n# Generate data for the plot\nx_values &lt;- seq(-10, 10, length.out = 101) # Range of x values\ny_values &lt;- sigmoid(x_values, L = 1, k = 1, x0 = 0) # Compute sigmoid values\ny_derivative &lt;- sigmoid_derivative(x_values, L = 1, k = 1, x0 = 0) # Compute first derivative\ny_second_derivative &lt;- sigmoid_second_derivative(x_values, L = 1, k = 1, x0 = 0) # Compute second derivative\ny_third_derivative &lt;- sigmoid_third_derivative(x_values, L = 1, k = 1, x0 = 0) # Compute third derivative\n\n# Create a data frame for ggplot\nsigmoid_data &lt;- data.frame(\n  x = x_values,\n  y = y_values,\n  y_derivative = y_derivative,\n  y_second_derivative = y_second_derivative,\n  y_third_derivative = y_third_derivative\n) %&gt;%\npivot_longer(\n  cols = c(y, y_derivative, y_second_derivative, y_third_derivative),\n  names_to = \"derivative\",\n  values_to = \"value\"\n) %&gt;%\nmutate(\n  derivative = factor(derivative, \n                      levels = c(\"y\", \"y_derivative\", \"y_second_derivative\", \"y_third_derivative\"),\n                      labels = c(\"Sigmoid\", \"First Derivative\", \"Second Derivative\", \"Third Derivative\"))\n)\n\nestimated_points &lt;- tibble(\n  x = c(2.2),\n  y = sigmoid(c(2.2)),\n  derivative = c(\"Sigmoid\")\n)\n\n# Plot the sigmoid function and its derivatives\nsigmoid_data %&gt;%\n  dplyr::filter(derivative == \"Sigmoid\") %&gt;%\n  ggplot(aes(x = x)) +\n  geom_line(aes(y = value, color = derivative), size = 1) +\n  geom_point(data = estimated_points, aes(x=x,y=y), color = \"black\", size = 4) +\n  geom_vline(xintercept = c(2.2), linetype = \"dashed\", color = \"black\", size = 0.5) +\n  labs(\n    title = \"Sigmoid Function and Its Derivatives\",\n    x = \"x\",\n    y = \"Value\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 20, face = \"bold\"),\n    axis.text = element_text(size = 14),\n    axis.title = element_text(size = 16)\n  ) +\n  scale_color_manual(\n    name = \"Legend\",\n    values = c(\"blue\", \"red\", \"green\", \"purple\"),\n    labels = c(\"Sigmoid\", \"First Derivative\", \"Second Derivative\", \"Third Derivative\")\n  )\n\n\n\n\n\n\n\n\nFigure 3: Sigmoid Function\n\n\n\n\n\nHow can we derive where this point lies on any sigmoid function? Let’s take a quick calculus detour:\nThank you to LLMs for taking care of the heavy-lifting in actually deriving these equations.\n\nFirst derivative: represents the slope of the function in question. Also referred to as the “rate” of the function. Taking the first derivative of the generalized sigmoid function in Equation 2, we get:\n\n\\[\n\\frac{d}{dx} P(x) = \\frac{L k e^{-k(x - x_0)}}{(1 + e^{-k(x - x_0)})^2}\n\\tag{4}\\]\n\nSecond derivative: represents the change in the slope of the function. Also referred to as the “acceleration” of the function. Taking the second derivative of the generalized sigmoid function in Equation 2 thus gives us:\n\n\\[\n\\frac{d^2}{dx^2} P(x) = \\frac{L k^2 e^{-k(x - x_0)}(1 - e^{-k(x - x_0)})}{(1 + e^{-k(x - x_0)})^3}\n\\tag{5}\\]\n\nThird derivative: represents the change in the acceleration of the function. Also referred to as the “jerk” of the function. And finally, taking the third derivative of the generalized sigmoid function in Equation 2 gives us:\n\n\\[\n\\frac{d^3}{dx^3} P(x) = \\frac{L k^3 e^{-k(x - x_0)}(1 - 4e^{-k(x - x_0)} + e^{-2k(x - x_0)})}{(1 + e^{-k(x - x_0)})^4}\n\\tag{6}\\]\nI previously mentioned that we’re interested in the change in the change of the learning rate. We can first reword this as the “change in the acceleration of the learning rate”, and can then simplify this to the “jerk” of the learning rate. In other terms, we’ll need to find the value of \\(x\\) that maximizes the third derivative of the sigmoid function. This might be a lot to take in so let’s visualize the sigmoid plot with its first through third derivaties in Figure 4.\n\n\nShow Me the Code!\nsigmoid_data %&gt;%\n#   dplyr::filter(derivative == \"Sigmoid\") %&gt;%\n  ggplot(aes(x = x)) +\n  geom_line(aes(y = value, color = derivative), size = 1) +\n  geom_point(data = estimated_points, aes(x=x,y=y), color = \"black\", size = 4) +\n  geom_vline(xintercept = c(2.2), linetype = \"dashed\", color = \"black\", size = 0.5) +\n  labs(\n    title = \"Sigmoid Function and Its Derivatives\",\n    x = \"x\",\n    y = \"Value\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 20, face = \"bold\"),\n    axis.text = element_text(size = 14),\n    axis.title = element_text(size = 16)\n  ) +\n  scale_color_manual(\n    name = \"Legend\",\n    values = c(\"blue\", \"red\", \"green\", \"purple\"),\n    labels = c(\"Sigmoid\", \"First Derivative\", \"Second Derivative\", \"Third Derivative\")\n  )\n\n\n\n\n\n\n\n\nFigure 4: Sigmoid Function and Its Derivatives\n\n\n\n\n\nSo, the point I plotted aligns almost perfectly with one of the local maxima of the third derivative of the sigmoid function. At this point, we could solve for this point analytically, find the fourth derivative, set it equal to zero, and solve for the corresponding \\(x\\) value. However, I think there’s already too much talk of derivatives in this post so we’ll simply filter our dataset for the \\(x\\) value at which the third derivative is max (for \\(x\\) values greater than zero).\n\n\n\n\nListing 4: Finding the inflection point of the third derivative of the sigmoid function\n\n\n\nShow Me the Code!\nsigmoid_data %&gt;%\ndplyr::filter(\n    derivative == \"Third Derivative\",\n    x &gt; 0\n) %&gt;%\nslice(which.max(value))\n\n\n\n\n\n# A tibble: 1 × 3\n      x derivative        value\n  &lt;dbl&gt; &lt;fct&gt;             &lt;dbl&gt;\n1  2.20 Third Derivative 0.0414\n\n\nMy estimate for this point was spot-on (I, ugh, have good vision I guess?) However, this is only useful for the basic sigmoid function–let’s generalize this. If you had looked at some of the previous plotting code, you might have noticed that I wrote some functions for the sigmoid function and its derivatives, repeated below in Listing 5. We can use these functions to find the point at which the third derivative is maximized for any sigmoid function, not just the one we fitted to our data.\n\n\n\n\nListing 5: Sigmoid function and its derivatives\n\n\n\nShow Me the Code!\n# Define the sigmoid function and its derivatives\nsigmoid &lt;- function(x, L = 1, k = 1, x0 = 0) {\n  L / (1 + exp(-k * (x - x0)))\n}\n\nsigmoid_derivative &lt;- function(x, L = 1, k = 1, x0 = 0) {\n  k * L * exp(-k * (x - x0)) / (1 + exp(-k * (x - x0)))^2\n}\n\nsigmoid_second_derivative &lt;- function(x, L = 1, k = 1, x0 = 0) {\n  k^2 * L * exp(-k * (x - x0)) * (1 - exp(-k * (x - x0))) / (1 + exp(-k * (x - x0)))^3\n}\n\nsigmoid_third_derivative &lt;- function(x, L = 1, k = 1, x0 = 0) {\n  k^3 * L * exp(-k * (x - x0)) * (1 - 4 * exp(-k * (x - x0)) + exp(-2 * k * (x - x0))) / (1 + exp(-k * (x - x0)))^4\n}\n\n\n\n\n\nIf we apply these functions to our fitted sigmoid model, we can find the point at which the third derivative is maximized. This will give us the “inflection point” at which the value of learning additional practice questions begins to take a nosedive.\n\n\n\n\nListing 6: Finding the inflection point of the sigmoid function for test taking\n\n\n\nShow Me the Code!\nsigmoid_third_derivative(\n  x = seq(0, 308, length.out = 309),\n  L = 1,\n  k = coef(sigmoid_model)[\"k\"],\n  x0 = 154\n) %&gt;%\ntibble(\n    x = seq(0, 308, length.out = 309),\n    value = .\n) %&gt;%\ndplyr::filter(x &gt; 154) %&gt;% # only look past the halfway point\nslice(which.max(value))\n\n\n\n\n\n# A tibble: 1 × 2\n      x     value\n  &lt;dbl&gt;     &lt;dbl&gt;\n1   188 0.0000131\n\n\nSo an X value of 188\n\n\nShow Me the Code!\n# Generate data for the plot\nx_values &lt;- seq(0, 308, length.out = 309) # Range of x values\ny_values &lt;- sigmoid(x_values, L = 1, k = 0.0677, x0 = 154) # Compute sigmoid values\ny_derivative &lt;- sigmoid_derivative(x_values, L = 1, k = 0.0677, x0 = 154) # Compute first derivative\ny_second_derivative &lt;- sigmoid_second_derivative(x_values, L = 1, k = 0.0677, x0 = 154) # Compute second derivative\ny_third_derivative &lt;- sigmoid_third_derivative(x_values, L = 1, k = 0.0677, x0 = 154) # Compute third derivative\n\n# Create a data frame for ggplot\nsigmoid_data_test &lt;- data.frame(\n  x = x_values,\n  y = y_values,\n  y_derivative = y_derivative,\n  y_second_derivative = y_second_derivative,\n  y_third_derivative = y_third_derivative\n) %&gt;%\npivot_longer(\n  cols = c(y, y_derivative, y_second_derivative, y_third_derivative),\n  names_to = \"derivative\",\n  values_to = \"value\"\n) %&gt;%\nmutate(\n  derivative = factor(derivative, \n                      levels = c(\"y\", \"y_derivative\", \"y_second_derivative\", \"y_third_derivative\"),\n                      labels = c(\"Sigmoid\", \"First Derivative\", \"Second Derivative\", \"Third Derivative\"))\n)\n\nestimated_points &lt;- tibble(\n  x = c(188),\n  y = sigmoid(c(188), L = 1, k = 0.0677, x0 = 154),\n  derivative = c(\"Sigmoid\")\n)\n\n# Plot the sigmoid function and its derivatives\nsigmoid_data_test %&gt;%\n  ggplot(aes(x = x)) +\n  geom_line(aes(y = value, color = derivative), size = 1) +\n  geom_point(data = estimated_points, aes(x=x,y=y), color = \"black\", size = 4) +\n  geom_vline(xintercept = c(188), linetype = \"dashed\", color = \"black\", size = 0.5) +\n  labs(\n    title = \"Sigmoid Function and Its Derivatives\",\n    x = \"x\",\n    y = \"Value\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 20, face = \"bold\"),\n    axis.text = element_text(size = 14),\n    axis.title = element_text(size = 16)\n  ) +\n  scale_color_manual(\n    name = \"Legend\",\n    values = c(\"blue\", \"red\", \"green\", \"purple\"),\n    labels = c(\"Sigmoid\", \"First Derivative\", \"Second Derivative\", \"Third Derivative\")\n  )\n\n\n\n\n\n\n\n\nFigure 5: Sigmoid Function and Its Derivatives for Test Taking\n\n\n\n\n\nA little bit hard to see what’s happening with the derivatives due to the scale of the y-axis; let’s take a look at just the third derivative of the sigmoid function in Figure 6. This plot shows the third derivative of the sigmoid function, which is where we find the “inflection point” that I was looking for.\n\n\nShow Me the Code!\n# Plot the sigmoid function and its derivatives\nsigmoid_data_test %&gt;%\n  filter(derivative == \"Third Derivative\") %&gt;%\n  ggplot(aes(x = x)) +\n  geom_line(aes(y = value, color = derivative), size = 1) +\n  geom_vline(xintercept = c(188), linetype = \"dashed\", color = \"black\", size = 0.5) +\n  labs(\n    title = \"Sigmoid Function 3rd Derivative\",\n    x = \"x\",\n    y = \"Value\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 20, face = \"bold\"),\n    axis.text = element_text(size = 14),\n    axis.title = element_text(size = 16)\n  ) +\n  scale_color_manual(\n    name = \"Legend\",\n    values = c(\"purple\"),\n    labels = c(\"Third Derivative\")\n  )\n\n\n\n\n\n\n\n\nFigure 6: Third Derivative of the Sigmoid Function\n\n\n\n\n\nThe point at which the third derivative is maximized is at 188, which corresponds to a probability of passing the test of 90.9%. This means that if I had answered 188 questions correctly on the practice test, I would have been at the point of increasing acceleration of diminishing returns in terms of learning additional practice questions. This is the point at which the value of learning additional practice questions begins to take a nosedive, and I would have been better off spending my time on other activities. In other words, I could have stopped studying after answering 188 questions correctly on the practice test and still had a very high probability of passing the actual test."
  },
  {
    "objectID": "fun_projects.html",
    "href": "fun_projects.html",
    "title": "Fun Projects",
    "section": "",
    "text": "The Best Sprint Coaching\n\n\nHave you ever wondered which US universities have the best sprint coaching programs? Probably not, but I did, so I made this project to find out. Specifically, I wanted to see which teams do the best job of developing sprinters. Take a look! \n\n\nin-progress!\nR\nSQLite\nwebscraping\nlinear mixed models\npatience\n\n\n\n\n\n\n  \n\n\nHave I Studied Enough to Pass?\n\n\nI had to take a test. I was tired of studying during vacation so I did what any reasonable person would do: I made a Monte Carlo simulation to see if I could stop studying. \n\n\nR\nsimulations\nprobability\ndata visualization\nprocrastination\n\n\n\n\n\n\n  \n\n\nMaster’s Thesis: Interrater Reliability of Cancer Tumor Response\n\n\nThis links directly out to my master’s thesis, which I completed in 2025. I did a deep dive into interrater reliability of the Response Evaluation Criteria in Solid Tumors (RECIST) for cancer tumor response. \n\n\nR\nclinical trials\ninterrater reliability\nsurvival analysis\novercaffeination\n\n\n\n\n\n\n  \n\n\n{ordinalsimr}: My First R Package on CRAN\n\n\nThis is my first R package, which I developed and released on CRAN in 2025. It provides a Shiny application for simulating ordinal data, and running a variety of statistical tests suited for ordinal data. It was a challenging project that taught me a lot about R package development and Shiny applications \n\n\nR package\nShiny\ndevelopment\nCRAN\nordinal data\nsimulations\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/munich-guide-intro.html",
    "href": "posts/munich-guide-intro.html",
    "title": "Munich Student Guide",
    "section": "",
    "text": "This page will detail the start (and long pause) in developing the Munich Student Guide site."
  },
  {
    "objectID": "posts/example2025.html",
    "href": "posts/example2025.html",
    "title": "Hello",
    "section": "",
    "text": "(This page is currently a placeholder)"
  },
  {
    "objectID": "posts/example2025.html#header2",
    "href": "posts/example2025.html#header2",
    "title": "Hello",
    "section": "header2",
    "text": "header2"
  },
  {
    "objectID": "posts/example2025.html#header3",
    "href": "posts/example2025.html#header3",
    "title": "Hello",
    "section": "header3",
    "text": "header3\n\nsubheader"
  },
  {
    "objectID": "posts/example2025.html#more-headers2",
    "href": "posts/example2025.html#more-headers2",
    "title": "Hello",
    "section": "more headers2",
    "text": "more headers2\n\n\nThis column takes 1/3 of the page\n\n\nThis column takes 2/3 of the page\n\n\nStart of a new grid section"
  },
  {
    "objectID": "posts/example2025.html#heres-a-subheader-in-a-column",
    "href": "posts/example2025.html#heres-a-subheader-in-a-column",
    "title": "Hello",
    "section": "here’s a subheader in a column",
    "text": "here’s a subheader in a column"
  },
  {
    "objectID": "posts/example2025.html#another-subheader-in-a-column",
    "href": "posts/example2025.html#another-subheader-in-a-column",
    "title": "Hello",
    "section": "another subheader in a column",
    "text": "another subheader in a column"
  },
  {
    "objectID": "posts/development.html",
    "href": "posts/development.html",
    "title": "ordinalsimr",
    "section": "",
    "text": "(This page is currently a placeholder)\nThis page should be designed in the spirit of one of the templates available here:\nhttps://quarto.org/docs/websites/website-about.html"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About Me\n\n\nWelcome to my personal blog and website! I am passionate about open science, reproducible research, and making complex scientific concepts accessible to everyone. This page provides an overview of my professional background, skills, and personal interests.\n\n\n\n\nProfessional Background\n\n\n\n[Your Current Job Title] at [Your Organization]\n\n\n[Start Date] - Present\n\n\n\n[Responsibility or Achievement 1]\n\n\n[Responsibility or Achievement 2]\n\n\n[Responsibility or Achievement 3]\n\n\n\n\n\n[Previous Job Title] at [Previous Organization]\n\n\n[Start Date] - [End Date]\n\n\n\n[Responsibility or Achievement 1]\n\n\n[Responsibility or Achievement 2]\n\n\n\n\n\n[Another Job Title] at [Another Organization]\n\n\n[Start Date] - [End Date]\n\n\n\n[Responsibility or Achievement 1]\n\n\n[Responsibility or Achievement 2]\n\n\n\n\n\n\nSkills\n\n\n\nProgramming Languages: R, Python, [Other Languages]\n\n\nTools & Technologies: Shiny, Quarto, [Other Tools]\n\n\nAreas of Expertise: Epidemiology, Data Analysis, [Other Areas]\n\n\n\n\n\nRecent Projects\n\n\n\n[Project Title 1]\n\n\nA brief description of the project and its significance. [Link to Project]\n\n\n\n\n[Project Title 2]\n\n\nA brief description of the project and its significance. [Link to Project]\n\n\n\n\n[Project Title 3]\n\n\nA brief description of the project and its significance. [Link to Project]\n\n\n\n\n\nPersonal Interests\n\n\nWhen I’m not working, I enjoy:\n\n\n\n[Hobby or Interest 1]\n\n\n[Hobby or Interest 2]\n\n\n[Hobby or Interest 3]"
  }
]